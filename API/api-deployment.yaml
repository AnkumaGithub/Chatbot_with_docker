apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: api
  template:
    metadata:
      labels:
        app: api
    spec:
      containers:
      - name: api-container
        image: api-service:latest
        imagePullPolicy: Never
        ports:
        - containerPort: 8000
        env:
        - name: LLM_SERVICE_URL
          value: "http://llm-service:8000/generate"
        - name: KAFKA_BOOTSTRAP_SERVERS
          value: "kafka-service:9092"
        - name: QDRANT_URL
          value: "http://qdrant-service:6333"
        - name: EMBEDDING_MODEL
          value: "all-MiniLM-L6-v2"
        - name: SIMILARITY_THRESHOLD
          value: "0.95"
---
apiVersion: v1
kind: Service
metadata:
  name: api-service
spec:
  selector:
    app: api
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 8000

---
# Перед тем как масштабировать нужно добавить Redis для изменения системы возврата ответов в API от LLM
#apiVersion: autoscaling/v2
#kind: HorizontalPodAutoscaler
#metadata:
#  name: api-hpa
#spec:
#  scaleTargetRef:
#    apiVersion: apps/v1
#    kind: Deployment
#    name: api-deployment
#  minReplicas: 1
#  maxReplicas: 5
#  metrics:
#  - type: Resource
#    resource:
#      name: cpu
#      target:
#        type: Utilization
#        averageUtilization: 80